# paths in config.yml are either an absolute path or relative to the repo directory
# path to checkpoint should be path to the parent dir (get the latest file inside) or a specific checkpoint file

dataset:
  train:
    module_name: fake
    kwargs:
      dataset_dir: data/k700-2020
      n_references: 3
      n_samples: 96
      batch_size: 32
      shuffle: True
      frame_rate: 6
  val:
    module_name: fake
    kwargs:
      dataset_dir: data/k700-2020
      n_references: 3
      n_samples: 16
      batch_size: 32
      shuffle: False
      frame_rate: 6
  predict:


transform:
  train:
    input:
      - module_name: v2ToImage        # torchvision.transforms.v2.ToImage
      - module_name: v2ToDtype        # torchvision.transforms.v2.ToDtype
        kwargs:
          dtype: torch.float32        # must be torch native dtype
          scale: True
      - module_name: v2Resize         # torchvision.transforms.v2.Resize
        kwargs:
          size: [256, 256]            # [height, width]
          antialias: True
      - module_name: v2Grayscale      # torchvision.transforms.v2.Grayscale
    label:
      - module_name: cv2Resize
        kwargs:
          size: [32, 32]              # [height, width]
      - module_name: cv2cvtColor
        kwargs:
          code: cv2.COLOR_BGR2LAB
      - module_name: ExtractChannel
        kwargs:
          channels: [1, 2]
      - module_name: Quantize
        kwargs:
          require_fit: True
          n_fit: 96
          model:
            module_name: KMeans
            kwargs:
              n_clusters: 16
          encoder: OneHotEncoder
          checkpoint_path: checkpoints/transform/Quantize
      - module_name: v2ToImage
          

model:
  backbone:
    module_name: resnet18
    kwargs:
      mid_channels: [64, 256, 256, 256]
      mid_strides: [1, 2, 1, 1]

  head:
    module_name: convnet3d
    kwargs:
      mid_channels: 256
      out_channels: 64
      dilations: [1, 2, 4, 8, 16]
  
  checkpoint_path: checkpoints/model/Colorizer




training:
  device: auto    # 'auto' or 'cuda:0' or 'cpu'
  loss: CrossEntropyLoss
  optimizer:
    module_name: Adam
    kwargs:
      lr: 0.001
  schedulers:
    - module_name: ReduceLROnPlateau
      kwargs:
        mode: min
        patience: 2
        verbose: True
  epochs: 15
  verbose_step: 1
  show_batch_queue_max_size: 3

prediction:
  device: cuda:0



logging:
  level: INFO
  format: " %(asctime)23s | %(module)10s | %(funcName)20s | %(lineno)5d | %(levelname)8s | %(message)s"
  handlers:
    file: logs   # directory to save log files
    stream: stdout
  datetime_format: '%Y%m%d_%H%M%S'